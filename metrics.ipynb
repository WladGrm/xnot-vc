{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbf0a1d-b92e-4365-854d-3e89bc195d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install speechbrain whisper jiwer -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "3ecd8719-a028-48c9-8cc2-b35cd5deac7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import whisper\n",
    "import jiwer\n",
    "import intel_extension_for_pytorch as ipex\n",
    "import torch\n",
    "import torchaudio\n",
    "import pathlib\n",
    "import collections\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "asr = whisper.load_model(\"base\", device=\"cpu\",)\n",
    "\n",
    "def calculate_wer_cer(reference_text, audio_file_path):\n",
    "    \n",
    "    # Transcribe the audio file\n",
    "    result = asr.transcribe(audio_file_path, )\n",
    "    transcribed_text = result['text']\n",
    "    \n",
    "    # Calculate WER\n",
    "    wer = jiwer.wer(reference_text, transcribed_text)\n",
    "    \n",
    "    # Calculate CER\n",
    "    cer = jiwer.cer(reference_text, transcribed_text)\n",
    "    \n",
    "    return wer, cer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "07d9a8e5-2f67-432f-9f12-202187850522",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = pathlib.Path(\"experiments/2300v2/\")\n",
    "\n",
    "with open(path.joinpath(\"valid ground truth.txt\"), \"r\") as f:\n",
    "    text = f.read().lower()\n",
    "\n",
    "reference_audio = path.joinpath(\"valid_long.flac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4eb1a1-6e41-4861-8693-2a921a79207e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "464e2c47-dc6d-42ec-b363-c59aaaee2806",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.11764705882352941, 0.017699115044247787)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wer_ref, cer_ref = calculate_wer_cer(text, reference_audio.as_posix())\n",
    "wer_ref, cer_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "296520a9-c773-41e6-8119-78aac71c4559",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "asr_knn_dict = collections.defaultdict(dict)\n",
    "\n",
    "for item in path.joinpath(\"to_male/results/knn-vc\").iterdir():\n",
    "    \n",
    "    wer, cer = calculate_wer_cer(text, item.as_posix())\n",
    "    \n",
    "    asr_knn_dict[item.stem + \"_male\"] = {\"wer\": wer, \"cer\": cer}\n",
    "    \n",
    "for item in path.joinpath(\"to_female/results/knn-vc\").iterdir():\n",
    "    \n",
    "    wer, cer = calculate_wer_cer(text, item.as_posix())\n",
    "    \n",
    "    asr_knn_dict[item.stem + \"_female\"] = {\"wer\": wer, \"cer\": cer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "08df5bbd-84a3-42cd-9c4b-54a2685144f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "asr_xnot_dict = collections.defaultdict(dict)\n",
    "\n",
    "for item in path.joinpath(\"to_male/results/xnot-vc\").iterdir():\n",
    "    \n",
    "    wer, cer = calculate_wer_cer(text, item.as_posix())\n",
    "    \n",
    "    asr_xnot_dict[item.stem + \"_male\"] = {\"wer\": wer, \"cer\": cer}\n",
    "    \n",
    "for item in path.joinpath(\"to_female/results/xnot-vc\").iterdir():\n",
    "    \n",
    "    wer, cer = calculate_wer_cer(text, item.as_posix())\n",
    "    \n",
    "    asr_xnot_dict[item.stem + \"_female\"] = {\"wer\": wer, \"cer\": cer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "649b9793-6697-4b4e-98a7-17bbbb70144c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "knn_df = pd.DataFrame.from_dict(asr_knn_dict).T\n",
    "xnot_df = pd.DataFrame.from_dict(asr_xnot_dict).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "1119950b-12c3-4e63-a64d-c68c3b43fdeb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wer</th>\n",
       "      <th>cer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.145588</td>\n",
       "      <td>0.025885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.027780</td>\n",
       "      <td>0.009334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.017699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.017699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.026549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.026549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.053097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             wer        cer\n",
       "count  20.000000  20.000000\n",
       "mean    0.145588   0.025885\n",
       "std     0.027780   0.009334\n",
       "min     0.117647   0.017699\n",
       "25%     0.117647   0.017699\n",
       "50%     0.147059   0.026549\n",
       "75%     0.147059   0.026549\n",
       "max     0.205882   0.053097"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "1558dcf0-f0c4-4b7e-9080-b1e36cd490bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wer</th>\n",
       "      <th>cer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.130882</td>\n",
       "      <td>0.021681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.015012</td>\n",
       "      <td>0.005156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.017699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.017699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.017699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.026549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.035398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             wer        cer\n",
       "count  20.000000  20.000000\n",
       "mean    0.130882   0.021681\n",
       "std     0.015012   0.005156\n",
       "min     0.117647   0.017699\n",
       "25%     0.117647   0.017699\n",
       "50%     0.117647   0.017699\n",
       "75%     0.147059   0.026549\n",
       "max     0.147059   0.035398"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xnot_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b2c130-7ebc-4052-9dc9-3dfb125697a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3739650-4215-4018-8846-d96f64c6be23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81617803-bb5b-483a-afbb-1313371bebe7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Synthvoice detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "fd8b38bd-adcf-4784-80d9-9a1bd27e0ce9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoFeatureExtractor, AutoModelForAudioClassification\n",
    "\n",
    "extractor = AutoFeatureExtractor.from_pretrained(\"MattyB95/AST-VoxCelebSpoof-Synthetic-Voice-Detection\")\n",
    "model = AutoModelForAudioClassification.from_pretrained(\"MattyB95/AST-VoxCelebSpoof-Synthetic-Voice-Detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "76694f7c-253d-4cec-bdc7-1504bedb63fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"audio-classification\", model=\"MattyB95/AST-ASVspoof5-Synthetic-Voice-Detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2484caf4-5594-42ef-9062-681fd473858c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "c5fb683f-ffac-46c8-ad24-64ba15020084",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch = extractor(*librosa.load(\"experiments/2300/valid_short.flac\", sr=16000), return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "5b07f9f1-e705-4d68-af8f-5fc5bc219483",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(model(**batch).logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "6c1e9c65-1b08-48d2-8fa9-2ee625177ea9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.999961256980896, 'label': 'Bonafide'},\n",
       " {'score': 3.877157359966077e-05, 'label': 'Spoof'}]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"experiments/2300/to_female/female_3575_v2.flac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c529eb8b-bee3-42b9-8f1f-a50566606cc5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1.0\n",
       "1     1.0\n",
       "2     1.0\n",
       "3     1.0\n",
       "4     1.0\n",
       "5     1.0\n",
       "6     1.0\n",
       "7     1.0\n",
       "8     1.0\n",
       "9     1.0\n",
       "10    1.0\n",
       "11    1.0\n",
       "12    1.0\n",
       "13    1.0\n",
       "14    1.0\n",
       "15    1.0\n",
       "16    1.0\n",
       "17    1.0\n",
       "18    1.0\n",
       "19    1.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asd_knn = []\n",
    "\n",
    "for item in path.joinpath(\"to_male/results/knn-vc\").iterdir():\n",
    "    \n",
    "    score = pipe(item.as_posix())[0][\"score\"]\n",
    "    asd_knn.append(score)\n",
    "    \n",
    "for item in path.joinpath(\"to_female/results/knn-vc\").iterdir():\n",
    "    \n",
    "    score = pipe(item.as_posix())[0][\"score\"]\n",
    "    asd_knn.append(score)\n",
    "    \n",
    "pd.Series(asd_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4faae80-a8f1-44a6-9015-4e6a30a306b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c3868a-f884-4718-8d4d-878cf25337cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a7f2317-beda-4cfc-b45d-1673b1338083",
   "metadata": {},
   "source": [
    "### EER calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "f569a0ff-db5b-4a20-848e-75242b6d0293",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = pathlib.Path(\"experiments/2300v2/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "3a0159d3-8298-40c4-aa3f-f5aef646735d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-11 03:11:19,388 - speechbrain.utils.fetching - INFO - Fetch hyperparams.yaml: Using existing file/symlink in pretrained_models/EncoderClassifier-e3dcc8e5060144ec1668cd02c05772cd/hyperparams.yaml.\n",
      "2024-08-11 03:11:19,389 - speechbrain.utils.fetching - INFO - Fetch custom.py: Delegating to Huggingface hub, source speechbrain/spkrec-xvect-voxceleb.\n",
      "2024-08-11 03:11:19,830 - speechbrain.utils.fetching - INFO - Fetch embedding_model.ckpt: Using existing file/symlink in pretrained_models/EncoderClassifier-e3dcc8e5060144ec1668cd02c05772cd/embedding_model.ckpt.\n",
      "2024-08-11 03:11:19,831 - speechbrain.utils.fetching - INFO - Fetch mean_var_norm_emb.ckpt: Using existing file/symlink in pretrained_models/EncoderClassifier-e3dcc8e5060144ec1668cd02c05772cd/mean_var_norm_emb.ckpt.\n",
      "2024-08-11 03:11:19,832 - speechbrain.utils.fetching - INFO - Fetch classifier.ckpt: Using existing file/symlink in pretrained_models/EncoderClassifier-e3dcc8e5060144ec1668cd02c05772cd/classifier.ckpt.\n",
      "2024-08-11 03:11:19,833 - speechbrain.utils.fetching - INFO - Fetch label_encoder.txt: Using existing file/symlink in pretrained_models/EncoderClassifier-e3dcc8e5060144ec1668cd02c05772cd/label_encoder.ckpt.\n",
      "2024-08-11 03:11:19,833 - speechbrain.utils.parameter_transfer - INFO - Loading pretrained files for: embedding_model, mean_var_norm_emb, classifier, label_encoder\n"
     ]
    }
   ],
   "source": [
    "from speechbrain.inference import EncoderClassifier\n",
    "speaker_enc = EncoderClassifier.from_hparams(\n",
    "  \"speechbrain/spkrec-xvect-voxceleb\"\n",
    ")\n",
    "\n",
    "speaker_enc.eval();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "2ff1b1c6-8767-47bc-b224-2dcddd3ec7f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_speaker_matrix(path, glob):\n",
    "\n",
    "    matrix = None\n",
    "\n",
    "    for p in path.joinpath(\"to_male\").rglob(glob):\n",
    "\n",
    "        signal, fs = torchaudio.load(p)\n",
    "        embeddings = speaker_enc.encode_batch(signal)\n",
    "\n",
    "        if matrix is None:\n",
    "            matrix = embeddings\n",
    "        else: \n",
    "            matrix = torch.cat((matrix, embeddings), dim=0)\n",
    "            \n",
    "    for p in path.joinpath(\"to_female\").rglob(glob):\n",
    "\n",
    "        signal, fs = torchaudio.load(p)\n",
    "        embeddings = speaker_enc.encode_batch(signal)\n",
    "        matrix = torch.cat((matrix, embeddings), dim=0)\n",
    "            \n",
    "    return matrix.squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "8b2a422b-eba2-449f-a32c-26b675a7b2e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ref_matrix = get_speaker_matrix(path, \"*_30.flac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "3a15760d-a29e-4849-8eeb-cc765349d313",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_matrix = get_speaker_matrix(path, \"*_v2.flac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "d7c00a2c-a6f9-47b8-8044-8596b12350a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "knn_matrix = get_speaker_matrix(path, \"knnvc*.flac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "21c9534b-5861-4567-981d-2927f699944f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xnot_matrix = get_speaker_matrix(path, \"xnotvc*.flac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "46e28005-bb7d-4422-a9e0-da4543f27347",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9294, 0.9473, 0.9373, 0.9429, 0.9315, 0.9551, 0.9448, 0.9471, 0.9487,\n",
       "        0.9338, 0.9673, 0.9563, 0.9355, 0.9556, 0.8978, 0.9488, 0.9977, 0.9586,\n",
       "        0.9258, 0.9605])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.cosine_similarity(ref_matrix, true_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "3adf671f-c2cf-4493-8d30-7bd7fbba171f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9423, 0.9498, 0.9358, 0.9440, 0.9435, 0.9475, 0.9773, 0.9360, 0.9557,\n",
       "        0.9281, 0.9238, 0.9515, 0.9440, 0.9464, 0.9166, 0.9796, 0.9837, 0.9561,\n",
       "        0.9306, 0.9413])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.cosine_similarity(ref_matrix, knn_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "1e55daf4-30a9-4c9c-ac74-2065569bbeb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9535, 0.9504, 0.9737, 0.9474, 0.9325, 0.9385, 0.9278, 0.9300, 0.9539,\n",
       "        0.9487, 0.9546, 0.9809, 0.9560, 0.9624, 0.9098, 0.9500, 0.9626, 0.9336,\n",
       "        0.9437, 0.9220])"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.cosine_similarity(ref_matrix, xnot_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e17a22-90bf-4d7f-837d-23427d987cbd",
   "metadata": {},
   "source": [
    "##### KNN-VC EER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "1ea69d9a-b2fc-469e-988b-1d72e9d8b732",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.44999998807907104, 0.9448345303535461)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speechbrain.utils.metric_stats.EER(\n",
    "    torch.nn.functional.cosine_similarity(ref_matrix, true_matrix),\n",
    "    torch.nn.functional.cosine_similarity(ref_matrix, knn_matrix)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130b7910-4ecd-4978-a6bf-645a5e75f0a8",
   "metadata": {},
   "source": [
    "##### XNOT-VC EER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "7bdebf0f-f6e0-4cf0-b953-6cbf62f72d44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.550000011920929, 0.9473746418952942)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speechbrain.utils.metric_stats.EER(\n",
    "    torch.nn.functional.cosine_similarity(ref_matrix, true_matrix),\n",
    "    torch.nn.functional.cosine_similarity(ref_matrix, xnot_matrix)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
